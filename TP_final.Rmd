---
title: "r_eval"
author: "aurelien"
date: "2022-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
df <- read.csv("C:/Users/Papa/Documents/R_eval/train.csv")

df=df[,-c(14,15)]
df$save=as.factor(df$save) # model will perform classification

set.seed(2)
summary(df)
str(df)


```
```{r}
library(rpart)
library(MASS)
library(caTools)
library(rpart.plot)
library(randomForest)
library(gbm)
library(xgboost)
library(caret)
library(ipred) #for bagging()
library(MLmetrics)
library("dplyr")
library("ggplot2")
library(tidyr)
library(corrplot)
library(FactoMineR)

sample = sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.8,0.2))


training_data = df[sample, ]
testing_data = df[!sample, ]
```
```{r}
REG_TO_CLASSIFICATION=function(a){ifelse(a < 0.5, 0, 1 )}
```


# choice of the model

we will be testing  :

Classification_tree
Bagged CART
RandomForest
Stochastic Gradient Boosting

based on Accuracy

## Classification_tree
```{r}

model_classification_tree = rpart(save~. , data=training_data)
prediction_model_classification_tree=REG_TO_CLASSIFICATION(predict(model_classification_tree,testing_data))

Accuracy(y_pred =prediction_model_classification_tree,y_true=testing_data$save)

```
## Bagged CART
```{r}
fitControl_bag = trainControl(method = "repeatedcv",number = 8,repeats = 3)
model_tune_bag = train(save ~ ., data = training_data, method = "treebag", trControl = fitControl_bag)
model_tune_bag
predict2=predict(model_tune_bag,testing_data)
Accuracy(y_pred =predict2,y_true=testing_data$save)

```
## RandomForest
```{r}
fitControl_RF = trainControl(method = "repeatedcv",number = 8,repeats = 3)
model_tune_RF = train(as.factor(save) ~ ., data = training_data, method = "rf", trControl = fitControl_RF)
model_tune_RF

predict3=predict(model_tune_RF,testing_data)
Accuracy(y_pred =predict3,y_true=testing_data$save)

```
## Stochastic Gradient Boosting

```{r}
fitControl = trainControl(method = "repeatedcv",number = 10,repeats = 3)
model_tune_boost = train(as.factor(save) ~ ., data = training_data, method = "gbm", trControl = fitControl,verbose = FALSE)
model_tune_boost

predict4=predict(model_tune_boost,testing_data)
Accuracy(y_pred =predict4,y_true=testing_data$save)
```




# Now we will use RandomForest provides the best results


base random forest
```{r}

model_Random_Forest=randomForest(save~. ,
                                 data=training_data,
                                 importance = TRUE,
                                 proximity = TRUE)
model_Random_Forest

prediction_model_Random_Forest=predict(model_Random_Forest,testing_data)
Accuracy(y_pred =prediction_model_Random_Forest,y_true=testing_data$save)

```



# we optimise randomForest


model_Random_Forest
```{r}
importance(model_Random_Forest)

```

```{r}
varImpPlot(model_Random_Forest)
```
```{r}
library(mlbench)
library(e1071)

#Create control function for training with 10 folds and keep 3 folds for training. search method is grid.
control <- trainControl(method='oob', 
                        number=6, 
                        search='grid',
                        adaptive = list(min = 5, alpha = 0.05, method = "gls", complete = TRUE))

#control2=trainControl(method = "repeatedcv",number = 10,repeats = 3)


#create tunegrid with 15 values from 1:15 for mtry to tunning model. Our train function will change number of entry variable at each split according to tunegrid. 
tunegrid <- expand.grid(.mtry = (1:5)) 
rf_gridsearch <- train(save ~ .-time_signature -key -mode , 
                       data = training_data,
                       method = 'rf',
                       metric = 'Accuracy',
                       tuneGrid = tunegrid,
                       trControl=control)
print(rf_gridsearch)
```
```{r}
plot(rf_gridsearch)
```
```{r}
predict5=predict(rf_gridsearch,testing_data)
Accuracy(y_pred =predict5,y_true=testing_data$save)
```
randomForest gives us the best and more stable prediction here



# PCA visualization

Show the correlation matrix of the quantitative variables.
```{r}
df <- read.csv("C:/Users/Papa/Documents/R_eval/train.csv")

df=df[,-c(14,15)]
res.pca <-PCA(df[,-c(14)], scale.unit = TRUE, graph = TRUE)
print(res.pca)

```
```{r}
var2 <- get_pca_var(res.pca)
corrplot(var2$cos2)
```
```{r}
library(ggplot2)
library(reshape2)

df2 <- melt(df, id.vars="save")
df2[1:3,]
```
```{r}
bar1 <- ggplot(data=df2, aes(x=save, y=value, fill=variable))
bar1 + geom_histogram(stat="identity", position="dodge")
```


```{r}
library(factoextra)
get_eigenvalue(res.pca)

```
```{r}
fviz_eig(res.pca,addlabels = TRUE)

```
```{r}
#Plot the correlation circle using the fviz_pca_var function.
fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

```
```{r}
fviz_contrib(res.pca, choice = "var", axes = 1:4)

```
we will take the first 7th features








```{r}
df_test <- read.csv("C:/Users/Papa/Documents/R_eval/test.csv")

df <- read.csv("C:/Users/Papa/Documents/R_eval/train.csv")
df=df[,-c(14,15)]
df$save=as.factor(df$save) # model will perform classification


df_test=df_test[,-c(14,15)]

training_data = df
testing_data = df_test


control <- trainControl(method='oob', 
                        number=6, 
                        search='grid',
                        adaptive = list(min = 5, alpha = 0.05, method = "gls", complete = TRUE))

tunegrid <- expand.grid(.mtry = (1:5)) 
rf_gridsearch <- train(save ~ .-time_signature -key -mode, 
                       data = training_data,
                       method = 'rf',
                       metric = 'Accuracy',
                       tuneGrid = tunegrid,
                       trControl=control)


prediction_final=predict(rf_gridsearch,testing_data)
```
```{r}
to_be_submitted = data.frame(id=rownames(df_test), save=prediction_final)
write.csv(to_be_submitted , file = "to_be_submitted.csv", row.names = F)
```











